---
title: "Data Analysis Using Statistical Packages: Regression Analysis"
author: "Sho Kuroda / 黒田翔"
date: '2024年3月 (Last update: 2024年3月)'
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Simple regression analysis / 単回帰分析

1つの説明変数をもつ次のような回帰モデル（単回帰モデル）を考える．

$$ Fertility = \alpha + \beta Examination + u $$

`lm` (linear model) 関数で推定する．

```{r reg_lm}
# str(swiss)  # built-in dataset
lm(formula = Fertility ~ Examination, data = swiss)
```

`lm` 関数で計算した回帰オブジェクトを `summary` 関数に渡すと決定係数なども表示される．

```{r reg_summary}
summary(lm(formula = Fertility ~ Examination, data = swiss))
```

## Estimation by hand

回帰係数の最小二乗（OLS）推定量は次のように与えられる．

$$ \hat{\alpha} = \bar{Y} - \hat{\beta} \bar{X}, \quad \hat{\beta} = \frac{S_{XY}}{S_{XX}} $$
$$ S_XX = \sum_i (X - \bar{X})^2, \quad S_XY = \sum_i (X - \bar{X}) (Y - \bar{Y}) $$

まず $\bar{Y}, \bar{X}, S_XX, S_YY$ という4つの統計量を計算する．

```{r reg_mean_s}
y_bar <- mean(swiss$Fertility)  # Y bar
x_bar <- mean(swiss$Examination)  # X bar
s_xx <- sum((swiss$Examination - x_bar)^2)  # S_XX
s_xy <- sum((swiss$Examination - x_bar) * (swiss$Fertility - y_bar))  # S_XX
y_bar; x_bar; s_xx; s_xy
```

計算した統計量を使って回帰係数を計算する．

```{r reg_coef}
beta_hat <- s_xy / s_xx
alpha_hat <- y_bar - beta_hat * x_bar
alpha_hat; beta_hat
```

残差（誤差変数の当てはめ値, $\hat{u}$）に関する次の性質を確認する．

$$ \sum_i \hat{u}_i = 0, \quad \sum_i \hat{u}_i X_i = 0 $$
$$ S_{X\hat{u}} = \sum_i (X - \bar{X}) (\hat{u} - \bar{\hat{u}}) = 0, \quad S_{Y\hat{u}} = \sum_i (Y - \bar{Y}) (\hat{u} - \bar{\hat{u}}) = 0 $$

```{r reg_check}
y_pred <- alpha_hat + beta_hat * swiss$Examination  # y hat
mean(y_pred); y_bar  # should be matched
resid_swiss <- swiss$Fertility - y_pred  # residuals
sum(resid_swiss)  # should be zero
sum(resid_swiss * swiss$Examination)  # eX ... should be zero
sum((swiss$Examination - x_bar) * (resid_swiss - mean(resid_swiss)))  # S_Xe ... should be zero
sum((y_pred - y_bar) * (resid_swiss - mean(resid_swiss)))  # S_Ye ... should be zero
```

## Estimation by numerical calculation / 数値計算による推定

OLSは残差二乗和の最小化によって回帰係数パラメタを推定する方法（＝モデルをデータに当てはめる原理）．
そこで，残差二乗和をパラメタの関数として定式化して数値計算によって推定してみる．

残差二乗和の関数（目的関数）の最小化はRにbuilt-inされている汎用の最適化関数 `optim` によって行う．

```{r reg_optim}
sum_of_squared_residuals <- function (beta_vector) {
  y <- swiss$Fertility
  x <- swiss$Examination
  sum((y - beta_vector[1] - beta_vector[2] * x)^2)
}
optim(par = c(0, 0), fn = sum_of_squared_residuals)
```

$\hat{\beta}_0 = 86.8$ に固定して $\hat{\beta}_1$ の値によって残差二乗和がどのように変化するかをプロットしてみる．

（ちょっと複雑なスクリプトなので，どのように動いているかは理解しなくてよい．）

```{r reg_optim_given_beta0_plot}
sum_of_squared_residuals_beta1 <- function (beta1) {
  y <- swiss$Fertility
  x <- swiss$Examination
  sum((y - 86.8 - beta1 * x)^2)
}
beta1_range <- seq(-3, 2, by = 0.01)
obj_fun <- sapply(beta1_range, sum_of_squared_residuals_beta1)
plot(x = beta1_range, y = obj_fun, type = "l", xlim = c(-3, 2))
abline(v = -1.01, col = 2)
```

## Coefficient of determination / 決定係数

$$ R^2 = \frac{S_{\hat{Y}\hat{Y}}}{S_{YY}} = 1 - \frac{\sum \hat{u}_i^2}{S_{YY}} $$

```{r reg_r2}
s_yy <- sum((swiss$Fertility - y_bar)^2)
s_yhyh <- sum((y_pred - y_bar)^2)
s_yhyh / s_yy  # R^2
1 - sum(resid_swiss^2) / s_yy  # R^2 ... should be the same as above
```

宿題：自由度調整済み決定係数を計算．

## Standard error / 標準誤差

$$ V(\hat{\beta}) = \frac{\sigma^2}{S_{XX}}, \quad \hat{\sigma}^2 = s^2 = \frac{1}{n - 2} \sum \hat{u}_i^2 $$

```{r reg_var}
beta_se <- sqrt(sum(resid_swiss^2)/(nrow(swiss) - 2) / s_xx)  # standard error
beta_se
beta_hat / beta_se  # t stat
```

t分布の2.5%臨界値（両側5%に対応）は？

```{r reg_t}
qt(p = 0.025, df = nrow(swiss) - 2)  # df: degree of freedom (自由度)
qt(p = c(0.005, 0.025, 0.975, 0.995), df = nrow(swiss) - 2)  # 1% and 5%
qt(p = 0.975, df = 10000)  # cf. df が大きければほとんど標準正規分布の場合と同じ
```

# Multiple regression analysis / 重回帰分析

2つの説明変数をもつ次のような回帰モデル（重回帰モデル）を考える．

$$ Fertility = \alpha + \beta_1 Examination + \beta_2 Education + u $$

```{r multiple_reg_lm}
summary(lm(Fertility ~ Examination + Education, data = swiss))
```

## Estimation by hand

重回帰モデルの回帰係数のOLS推定量は行列形式で表現した方が分かりやすい．

式中の $\mathbf{X}, \mathbf{Y}$ は（$X, Y$ とは異なり）太字かつ立体（斜体ではない）になっており，これは行列またはベクトルを表す．

つまり，以下のように定義されている．
$X_{nm}$ は $n$ 番目の個体の $m$ 番目の説明変数を表す．
$Y_{n}$ は $n$ 番目の個体の被説明変数（アウトカム）を表す．

$$ \mathbf{X} = \left[ \matrix{X_{11} & X_{12} & X_{13} & \cdots \\ X_{21} & X_{22} & X_{23} & \cdots \\ X_{31} & X_{32} & X_{33} & \cdots \\ \vdots & \vdots & \vdots & \ddots} \right], \quad \mathbf{Y} = \left[ \matrix{Y_1 \\ Y_2 \\ Y_3 \\ \vdots} \right] $$

注：本当は $\beta$ も同様にベクトル表記するべきだが，このページ（R Markdown）を作成するための数式レンダリング機能の限界でスカラーのように出力されてしまっている．ベクトルとして読んでいただきたい．

$$ \hat{\mathbf{\beta}} = (\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\mathbf{Y} $$

まずは $\mathbf{X}, \mathbf{Y}$ を作成する．
説明変数には1（定数項）が含まれている点に注意しよう．

```{r reg_mr_XY_def}
Y <- as.matrix(swiss[, c("Fertility")])
X <- as.matrix(cbind(1, swiss[, c("Examination", "Education")]))
```

転置は `t`，逆行列は `solve`，行列の積は `%*%` で計算できるので，回帰係数のOLS推定量は以下のように計算される．

```{r reg_mr_estimation}
beta_multi <- solve(t(X) %*% X) %*% t(X) %*% Y
beta_multi
```

## Standard error / 標準誤差

$$ V(\hat{\mathbf{\beta}}) = \sigma^2 (\mathbf{X}'\mathbf{X})^{-1} $$

回帰係数の検定を行うためには誤差分散 $\sigma^2$ の推定値を求める必要がある．
$k$ は（定数項を除いた）説明変数の数なので2である．

$$ \hat{\sigma}^2 = \frac{1}{n-(1+k)} \sum_i (Y_i - \hat{Y}_i)^2 $$

```{r reg_mr_est_sigma2}
resid_multi <- Y - X %*% beta_multi
s2 <- sum(resid_multi^2) / (nrow(swiss)-3)  # estimates of sigma^2
s2
```

回帰係数の推定量ベクトルの分散は $\sigma^2 (\mathbf{X}'\mathbf{X})^{-1}$ （分散共分散行列）なので，個々の回帰係数の推定量の分散はこの分散共分散行列の対角成分である．

```{r reg_mr_var_beta}
s2 * solve(t(X) %*% X)  # variance-covariance matrix of beta 
diag(s2 * solve(t(X) %*% X))  # extract diagonals
```

標準誤差はその平方根となる．
すなわち，$j$ 番目の説明変数の標準誤差は次のように計算される．

$$ s.e.(\hat{\beta}_j) = \sqrt{\{\sigma^2 (\mathbf{X}'\mathbf{X})^{-1} \}_{jj}} $$

```{r reg_mr_std_error}
sqrt(diag(s2 * solve(t(X) %*% X)))  # standard errors 
```

回帰係数の推定値を標準誤差で割れば t 値が求められる．

```{r reg_mr_t}
t_value <- beta_multi / sqrt(diag(s2 * solve(t(X) %*% X)))
t_value
```

t 値 ($t^*$) が分かれば p 値も計算できる．

$$ p = 2 \times (1 - \Pr(|t^*| \le T)) $$

```{r reg_mr_p}
2 * (1 - pt(q = abs(t_value), df = nrow(swiss) - 3))
```


# Adcanced method / 応用

## Adding quardatic or interaction terms / 二次・交差項

新しい変数を作成するなどのデータフレームの操作をするためには `tidyverse` に含まれる関数 (`mutate`, `rename`, `group_by`, etc.) を用いると簡単．

```{r reg_mod, message = F}
# install.packages("tidyverse")  # 一度だけ実行
library(tidyverse)  # Rを立ち上げるたびに実行
```

```{r reg_mod2}
swiss2 <- swiss %>%
  mutate(Edu2 = Education^2,
         ExamEdu = Examination * Education)
lm(Fertility ~ Examination + Edu2, data = swiss2)
lm(Fertility ~ ExamEdu, data = swiss2)
```

データセットを直接操作せずに，回帰モデルを指定する際に `I` 関数を使って二乗や交差項を表現することもできる．「`var1 : var2`」は「`var1 × var2`」を表し，「`var1 * var2`」は「`var1 + var2 + (var1 × var2)`」を表す．

```{r reg_mod3}
lm(Fertility ~ Examination + I(Education^2), data = swiss)
lm(Fertility ~ Examination:Education, data = swiss)
lm(Fertility ~ Examination*Education, data = swiss)
```

説明変数や被説明変数に対数を取る場合は `I` なしで `log` を使ってよい．

```{r reg_log}
lm(log(Fertility) ~ Examination, data = swiss)
```

## Dummy variables ダミー変数

`Examination` 変数が平均よりも大きい場合に 1 をとるダミー変数を定義してみる．

```{r reg_dum}
swiss2 <- swiss %>%
  mutate(exam_dummy = ifelse(Examination > mean(Examination), 1, 0))
swiss2 %>%
  group_by(exam_dummy) %>%
  summarise(mean_fertility = mean(Fertility))
lm(Fertility ~ exam_dummy, data = swiss2)
```

以下のように回帰式を指定することで表現することもできる．

```{r reg_dum2}
lm(Fertility ~ I(Examination > mean(Examination)), data = swiss2)
```

## Joint hypothesis test / 結合有意性検定

「`Education` と `Examination` のどちらの回帰係数も 0 に等しい」という帰無仮説を検定するためには Joint test を行う．

$$ H_0: \beta_{Ed} = \beta_{Ex} = 0 $$
$$ F = \chi^2 \frac{1}{G} = \frac{(Q_R - Q) / 2}{Q / (n-k-1)} \sim F(G, n-k-1) $$

$Q$ は制約なしのモデル（対立仮説に対応．つまり，`Education` と `Examination` の2つの変数を説明変数として含むモデル）の残差二乗和を表す．

$Q_R$ は制約あり (restricted) のモデル（帰無仮説に対応．つまり，`Education` と `Examination` の2つの変数を説明変数として含まないモデル）の残差二乗和を表す．

```{r reg_joint}
lm_swiss_unrestricted <- lm(Fertility ~ Examination + Education, data = swiss)
lm_swiss_restricted <- lm(Fertility ~ 1, data = swiss)
resid_unrestricted <- sum(lm_swiss_unrestricted$resid^2)
resid_restricted <- sum(lm_swiss_restricted$resid^2)
```

計算した $Q, Q_R$ を用いて $F$ 値を計算し，臨界値と比較する．

```{r reg_joint_f}
((resid_restricted - resid_unrestricted) / 2) / (resid_unrestricted / (nrow(swiss) - 2 - 1))  # F
qf(p = 0.05, df1 = 2, df2 = nrow(swiss) - 2 - 1, lower.tail = F)  # critical value 
# qf(p = 0.95, df1 = 2, df2 = nrow(swiss) - 2 - 1, lower.tail = T)  # same as above
```

$F \approx 22.5 > \mbox{critical value}$ なので，帰無仮説は5%有意水準で棄却される．
すなわち，`Education` と `Examination` という2つの説明変数のうち少なくともいずれか一方の回帰係数は0ではないと結論付けられる．


### Using `car::linearHypothesis` function 

`car` というパッケージの `linearHypothesis` という関数で検定できる．
「`car::linearHypothesis`」のようにパッケージ名と関数名を `::` で繋いで使用すれば，当該パッケージを読み込まなくても関数を使える．

```{r reg_joint2}
lm_swiss <- lm(Fertility ~ Examination + Education, data = swiss)
summary(lm_swiss)
car::linearHypothesis(lm_swiss, "Examination = 0")
```

p値はどちらも 0.0206 となっていることが確認できる．

$$ H_0: \beta_{Ed} = \beta_{Ex} = 0 $$

```{r reg_joint3, eval = FALSE}
car::linearHypothesis(lm_swiss, c("Examination = 0", "Education = 0"))
```

（出力は省略）

$$ H_0: \beta_{Ed} + \beta_{Ex} = 1 $$

```{r reg_joint4, eval = FALSE}
car::linearHypothesis(lm_swiss, "Examination + Education = 1")
```

（出力は省略）

See alos: <https://www.econometrics-with-r.org/7.3-joint-hypothesis-testing-using-the-f-statistic.html>


## White standard error / ホワイトの標準誤差

残差 $\hat{u} = Y - \hat{Y}$ を用いた不均一分散に頑健な標準誤差（White によるオリジナルの方法）．

$$ s.e.(\hat{\beta}) = \sqrt{ \frac{\sum_i (X_i - \bar{X})^2 \hat{u}_i^2}{\left[\sum_i (X_i - \bar{X})^2\right]^2} } $$

```{r reg_white}
x <- swiss$Examination
lm_swiss <- lm(Fertility ~ Examination, data = swiss)
sqrt(sum((x - mean(x))^2 * lm_swiss$resid^2) / (sum((x - mean(x))^2))^2)  # White SE (original)
```

誤差分散を不偏推定するために自由度を調整する場合（一般に HC1 として知られる）．

$$ s.e._{HC1}(\hat{\beta}) = \sqrt{ \frac{n}{n-(k+1)} \frac{\sum_i (X_i - \bar{X})^2 \hat{u}_i^2}{\left[\sum_i (X_i - \bar{X})^2\right]^2} } $$

```{r reg_white_modified}
sqrt(nrow(swiss) / (nrow(swiss) - 2) * sum((x - mean(x))^2 * lm_swiss$resid^2) / (sum((x - mean(x))^2))^2)
```

`fixest` パッケージで推定する場合．

```{r reg_white2}
# install.packages("fixest")
library(fixest)
feols(Fertility ~ Examination, data = swiss, vcov = "hetero")
```
<!--
https://cran.r-project.org/web/packages/fixest/vignettes/standard_errors.html

# sqrt(diag(car::hccm(model = lm_swiss, type = "hc1")))  # using "car" package
# lmtest::coeftest(lm_swiss, vcov. = sandwich::vcovHC(lm_swiss, type="HC1"))  # using "lmtest" and "sandwich" packages
-->


## Cluster robust SE / クラスターロバスト標準誤差

以下の6地域をクラスターとして利用する（正確性・妥当性は未検証）．

A: ジュラカントン, B: ヴォー州, C: フリブール州, D: ネウシャテル州, E: ジュネーブ州, F: ヴァレー州

```{r reg_cluster}
library(fixest)
swiss2 <- swiss
swiss2$region <- 
  c("A", "A", "A", "A", "A", "A", "C", "C", "C", "C",
    "C", "B", "B", "B", "B", "B", "B", "B", "B", "B",
    "B", "B", "B", "B", "B", "B", "B", "B", "B", "B",
    "F", "F", "F", "F", "F", "F", "F", "F", "D", "D",
    "D", "D", "D", "D", "E", "E", "E")
table(swiss2$region)
feols(Fertility ~ Examination, data = swiss2, cluster = ~ region)
```


## OLS vs. WLS Monte Carlo simulation / モンテカルロシミュレーション

誤差の不均一性をもたらす要因が既知の場合は加重最小二乗法（WLS）の方が効率よく推定できる．

鹿野先生『計量経済学』で行われたシミュレーションを再現してみる．

OLS:

$$ Y_i = 1 + X_i + \sqrt{h} \tilde{u}_i $$
$$ X_i \sim N(0, 1) , \quad \tilde{u}_i \sim \mbox{Uni}(0, 4 \sqrt{12}), \quad h_i \sim \mbox{Uni}(0, 1) $$

WLS:

$$ \frac{Y_i}{\sqrt{h_i}} = \frac{1}{\sqrt{h_i}} + \beta \frac{X_i}{\sqrt{h_i}} + u_i $$

注：$E(u_i) \ne 0$ であるため，WLSで定数項を0にして推定してはいけない．

```{r reg_mc}
ols_matrix <- wls_matrix <- NULL
for (i in 1:1000) {
  set.seed(i)
  n <- 50
  x <- rnorm(n, 0, 1)
  u_tilde <- runif(n, 0, 4*sqrt(12))
  h <- runif(n, 0, 1)
  u <- u_tilde * h
  # OLS
  y <- 1 + x + u
  ols_matrix <- rbind(ols_matrix, lm(y ~ x)$coef)
  # WLS
  y_tilde <- y / sqrt(h)
  Ii <- 1 / sqrt(h)
  x_tilde <- x / sqrt(h)
  wls_matrix <- rbind(wls_matrix, lm(y_tilde ~ x_tilde)$coef)
}
summary(wls_matrix[, 2]); summary(ols_matrix[, 2])
hist(wls_matrix[, 2], breaks = 30)
hist(ols_matrix[, 2], breaks = 20, add = T, col = rgb(1,0,0, alpha = .2))
legend(x = "topright", col = c(8, 2), legend = c("WLS", "OLS"), lwd = 5)
```

<!--
plot(wls_matrix[, 2], ols_matrix[, 2], xlab = "beta of WLS", ylab = "beta of OLS", pch = ".")
abline(a = 0, b = 1, col = 2)
-->

.
